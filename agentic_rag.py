# -*- coding: utf-8 -*-
"""Agentic_RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fmBR97ch9y__l2WbBHHGtER-NoeOx5lt
"""

!pip install --quiet -U langchain langchainhub langchain_community langchain-tools openai langgraph langchain_groq python-dotenv langchain_experimental duckduckgo-search groq pypdf chromadb

from langchain_groq import ChatGroq
from google.colab import userdata

groq_api = userdata.get('groq_api')

from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceHubEmbeddings
from langchain.agents import initialize_agent, Tool
from langchain.document_loaders import PyPDFLoader
from langchain.tools import StructuredTool
from pydantic import BaseModel, Field


class PDFinput(BaseModel):
    pdf_path: str = Field(description="path to the PDF")
    query: str = Field(description="Query to be searched")
    top_k: int = Field(description="Documents to be retrieved")


def extract_pdf(pdf_path: str, query: str, top_k: int = 3):
    """Extract text from a PDF and store it in a vectorDB using HuggingFace embeddings."""
    embed_model = HuggingFaceHubEmbeddings(
        repo_id="sentence-transformers/all-mpnet-base-v2",
        huggingfacehub_api_token=userdata.get('huggingface')
    )

    loader = PyPDFLoader(pdf_path)
    pages = loader.load_and_split()
    texts = [page.page_content for page in pages]
    db = Chroma.from_texts(texts, embedding=embed_model)
    search_results = db.similarity_search(query, k=top_k)
    result_text = "\n".join([result.page_content for result in search_results])

    return result_text

def create_tools():
    return [
    Tool(
        name="extract_pdf",
        func=extract_pdf,
        description="Extracts text from a PDF file and stores it in a vector database."
    ),
]
PDF_extractor = StructuredTool.from_function(
    func=extract_pdf,
    name="extract_pdf",
    description="extract PDF and save it into vectorDB.",
    args_schema=PDFinput,
    return_direct=True,
)

def create_retriever_agent(PDF_extractor):
    """
    Create and initialize the retriever agent with the Chroma vector store.
    """
    llm = ChatGroq(api_key=groq_api, model="llama-3.2-90b-text-preview")
    tools = [PDF_extractor]

    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent="structured-chat-zero-shot-react-description",
        verbose=True
    )

    return agent




if __name__ == "__main__":
    pdf_path = "/content/ISME2024_Track1_066. R1.pdf"
    query = "Query: What are the list of components used?; Path to doc: /content/ISME2024_Track1_066. R1.pdf"
    top_k = 3
    query_input = {
    "pdf_path": "/content/ISME2024_Track1_066. R1.pdf",
    "query": "What are the list of components used?",
    "top_k": 3
    }
    print("Creating the agent...")
    agent = create_retriever_agent(PDF_extractor)

    print("Invoking the agent...")
    result = agent.invoke({"input" : query,
                           "pdf_path" : pdf_path,
                           "top_k" : top_k})
    print("\nRetrieved Results:")
    print(result)

if __name__ == "__main__":
    query = "Query: What are the characteristics of python?; Path to doc: /content/Python Full Tutorial.pdf; top_k: 5"

    print("Creating the agent...")
    agent = create_retriever_agent(PDF_extractor)

    print("Invoking the agent...")
    # Pass the query dynamically to the agent
    result = agent.invoke({"input" : query})

    print("\nRetrieved Results:")
    print(result)

if __name__ == "__main__":
    query = "Query: What are the applications of python?; Path to doc: /content/Python Full Tutorial.pdf; top_k: 5"

    print("Creating the agent...")
    agent = create_retriever_agent(PDF_extractor)

    print("Invoking the agent...")
    # Pass the query dynamically to the agent
    result = agent.invoke({"input" : query})

    print("\nRetrieved Results:")
    print(result)
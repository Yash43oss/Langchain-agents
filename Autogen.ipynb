{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuxelkeS3pOpvxV12djOUc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash43oss/Langchain-agents/blob/main/Autogen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autogen Agents using Groq Endpoint**"
      ],
      "metadata": {
        "id": "GsWQ93yFvREV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Installing dependancies\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R_BG1RQPv8Ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zwl-A-J0LzwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5da6a9cb-376e-42da-cfb6-051f64530981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: pyautogen in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: autogen-agentchat in /usr/local/lib/python3.10/dist-packages (0.2.38)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.12.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.3.19)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from pyautogen) (7.1.0)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen) (24.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (0.1.143)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2024.9.11)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq openai pyautogen\n",
        "!pip install 'autogen-agentchat==0.4.0.dev6'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Setting up agents using an Autogen prompt\n"
      ],
      "metadata": {
        "id": "1W_1NCKjwGmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent, AssistantAgent\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "from autogen_agentchat.task import MaxMessageTermination, TextMentionTermination\n",
        "\n",
        "\n",
        "code_writer_system_message = \"\"\"You are an AI assistant skilled in coding and language tasks. Provide solutions with Python (`python` code block) or shell script (`sh` code block).\n",
        "1. For info gathering, output necessary info (e.g., web browse, file read, system check). Use your language skills to solve the task after info is collected.\n",
        "2. For task execution, perform and output results. Clearly explain steps, indicating code or language skill. Solve step-by-step if needed. Plan first if not provided. Use full, executable code.\n",
        "Correct errors if they arise. Provide full code instead of partial solutions. Adapt approach if initial attempts fail.\n",
        "Do not formulate any type of conversation. Once you provide solution with code, End with 'TERMINATE'.\n",
        "\"\"\"\n",
        "\n",
        "text_termination = TextMentionTermination(\"TERMINATE\")\n",
        "\n",
        "code_writer_agent = ConversableAgent(\n",
        "    \"code_writer_agent\",\n",
        "    system_message=code_writer_system_message,\n",
        "    llm_config={\"config_list\": [{\"api_type\" : \"groq\",\n",
        "                                 \"model\": \"llama-3.2-90b-text-preview\",\n",
        "                                 \"api_key\": userdata.get(\"groq_api\"),\n",
        "                                 \"base_url\": \"https://api.groq.com/openai/v1\",\n",
        "                                 }]},\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    # is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"].lower(),\n",
        ")\n",
        "\n",
        "\n",
        "assistant_agent = AssistantAgent(name=\"assistant_agent\", is_termination_msg=text_termination)\n",
        "\n",
        "chat_result = assistant_agent.initiate_chat(\n",
        "    code_writer_agent,\n",
        "    termination_condition=text_termination,\n",
        "    message=\"Write Python code to calculate the 14th Fibonacci number.\",\n",
        "    # max_turns=2 ## Use if text_termination does not work\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ8ZCHfQ5Jrd",
        "outputId": "64ce9817-3515-4c9c-e5db-381a2aea1e59"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant_agent (to code_writer_agent):\n",
            "\n",
            "Write Python code to calculate the 14th Fibonacci number.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to assistant_agent):\n",
            "\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    \"\"\"\n",
            "    Calculate the nth Fibonacci number.\n",
            "\n",
            "    Args:\n",
            "    n (int): The position of the Fibonacci number to calculate.\n",
            "\n",
            "    Returns:\n",
            "    int: The nth Fibonacci number.\n",
            "    \"\"\"\n",
            "    if n <= 0:\n",
            "        return \"Input should be positive integer\"\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 2:\n",
            "        return 1\n",
            "    else:\n",
            "        fib_sequence = [0, 1]\n",
            "        while len(fib_sequence) < n:\n",
            "            fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
            "        return fib_sequence[-1]\n",
            "\n",
            "\n",
            "# Example usage:\n",
            "n = 14\n",
            "result = fibonacci(n)\n",
            "print(f\"The {n}th Fibonacci number is: {result}\")\n",
            "```\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Using Userproxy agent to allow human insights\n"
      ],
      "metadata": {
        "id": "NTemYkRFweIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent, UserProxyAgent\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "from autogen_agentchat.task import MaxMessageTermination, TextMentionTermination\n",
        "\n",
        "\n",
        "code_writer_system_message = \"\"\"You are an AI assistant skilled in coding and language tasks. Provide solutions with Python (`python` code block) or shell script (`sh` code block).\n",
        "1. For info gathering, output necessary info (e.g., web browse, file read, system check). Use your language skills to solve the task after info is collected.\n",
        "2. For task execution, perform and output results. Clearly explain steps, indicating code or language skill. Solve step-by-step if needed. Plan first if not provided. Use full, executable code.\n",
        "Correct errors if they arise. Provide full code instead of partial solutions. Adapt approach if initial attempts fail.\n",
        "Do not formulate any type of conversation. Once you provide solution with code, End with 'TERMINATE'.\n",
        "\"\"\"\n",
        "\n",
        "text_termination = TextMentionTermination(\"TERMINATE\")\n",
        "\n",
        "code_writer_agent = ConversableAgent(\n",
        "    \"code_writer_agent\",\n",
        "    system_message=code_writer_system_message,\n",
        "    llm_config={\"config_list\": [{\"api_type\" : \"groq\",\n",
        "                                 \"model\": \"llama-3.2-90b-text-preview\",\n",
        "                                 \"api_key\": userdata.get(\"groq_api\"),\n",
        "                                 \"base_url\": \"https://api.groq.com/openai/v1\",\n",
        "                                 }]},\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    # is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"].lower(),\n",
        ")\n",
        "\n",
        "\n",
        "assistant_agent = UserProxyAgent(name=\"assistant_agent\", is_termination_msg=text_termination, human_input_mode='ALWAYS')\n",
        "\n",
        "chat_result = assistant_agent.initiate_chat(\n",
        "    code_writer_agent,\n",
        "    termination_condition=text_termination,\n",
        "    message=\"Write Python code find outliers in any csv dataset.\",\n",
        "    # max_turns=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jctoUYxosRpS",
        "outputId": "50600545-f707-446a-eeb1-3dfc033effae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant_agent (to code_writer_agent):\n",
            "\n",
            "Write Python code find outliers in any csv dataset.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to assistant_agent):\n",
            "\n",
            "**Detecting Outliers in a CSV Dataset using Python**\n",
            "=====================================================\n",
            "\n",
            "This code will use the IQR (Interquartile Range) method to detect outliers in a given CSV dataset.\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "# Function to detect outliers\n",
            "def detect_outliers(df):\n",
            "    \"\"\"\n",
            "    Detects outliers in a given DataFrame.\n",
            "\n",
            "    Args:\n",
            "        df (pd.DataFrame): Input DataFrame.\n",
            "\n",
            "    Returns:\n",
            "        outliers (list): List of outlier indices.\n",
            "    \"\"\"\n",
            "    outliers = []\n",
            "    for col in df.columns:\n",
            "        if df[col].dtype in ['int64', 'float64']:\n",
            "            q1 = df[col].quantile(0.25)\n",
            "            q3 = df[col].quantile(0.75)\n",
            "            iqr = q3 - q1\n",
            "            lower_bound = q1 - 1.5 * iqr\n",
            "            upper_bound = q3 + 1.5 * iqr\n",
            "            col_outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()\n",
            "            outliers.extend(col_outliers)\n",
            "    return list(set(outliers))\n",
            "\n",
            "# Load CSV dataset\n",
            "def load_csv(file_path):\n",
            "    \"\"\"\n",
            "    Loads a CSV file into a DataFrame.\n",
            "\n",
            "    Args:\n",
            "        file_path (str): Path to the CSV file.\n",
            "\n",
            "    Returns:\n",
            "        df (pd.DataFrame): Loaded DataFrame.\n",
            "    \"\"\"\n",
            "    try:\n",
            "        df = pd.read_csv(file_path)\n",
            "        return df\n",
            "    except Exception as e:\n",
            "        print(f\"Failed to load CSV file: {str(e)}\")\n",
            "        return None\n",
            "\n",
            "# Main function\n",
            "def main():\n",
            "    file_path = 'data.csv'  # Replace with your CSV file path\n",
            "    df = load_csv(file_path)\n",
            "    if df is not None:\n",
            "        outliers = detect_outliers(df)\n",
            "        print(\"Outlier indices:\")\n",
            "        print(outliers)\n",
            "        print(\"Outlier values:\")\n",
            "        print(df.loc[outliers])\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n",
            "\n",
            "**Code Explanation:**\n",
            "------------------\n",
            "\n",
            "1.  We start by importing the necessary libraries, `pandas` for data manipulation and `numpy` for numerical computations.\n",
            "2.  We define a function `detect_outliers` that takes a DataFrame as input and returns a list of outlier indices.\n",
            "3.  Inside the function, we iterate through each column of the DataFrame. If the column is of numeric type (`int64` or `float64`), we calculate the interquartile range (IQR) and detect outliers using the IQR method.\n",
            "4.  We define another function `load_csv` that loads a CSV file into a DataFrame.\n",
            "5.  In the `main` function, we load the CSV file, detect outliers, and print the outlier indices and values.\n",
            "\n",
            "**Replace 'data.csv' with your actual CSV file path.**\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogen/oai/groq.py:280: UserWarning: Cost calculation not available for model llama-3.2-90b-text-preview\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Replying as assistant_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: how to download the mentioned libraries\n",
            "assistant_agent (to code_writer_agent):\n",
            "\n",
            "how to download the mentioned libraries\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to assistant_agent):\n",
            "\n",
            "**Downloading and Installing Pandas and NumPy Libraries**\n",
            "=====================================================\n",
            "\n",
            "You can download and install Pandas and NumPy libraries using pip, which is the package installer for Python.\n",
            "\n",
            "**Using pip:**\n",
            "---------------\n",
            "\n",
            "1.  Open a terminal or command prompt.\n",
            "2.  Type the following commands and press Enter:\n",
            "    ```sh\n",
            "pip install pandas\n",
            "pip install numpy\n",
            "```\n",
            "\n",
            "**Using conda (Optional):**\n",
            "-------------------------\n",
            "\n",
            "If you are using Anaconda distribution, you can install the libraries using conda:\n",
            "\n",
            "1.  Open a terminal or command prompt.\n",
            "2.  Type the following commands and press Enter:\n",
            "    ```sh\n",
            "conda install pandas\n",
            "conda install numpy\n",
            "```\n",
            "\n",
            "**Using a Python IDE (PyCharm, Visual Studio Code, etc.):**\n",
            "--------------------------------------------------------\n",
            "\n",
            "Most modern Python Integrated Development Environments (IDEs) have built-in support for package installation.\n",
            "\n",
            "For example, in PyCharm:\n",
            "\n",
            "1.  Open your project.\n",
            "2.  Click on `File` > `Settings` > `Project: [Your Project Name]` > `Python Interpreter`.\n",
            "3.  Click on the `+` button at the bottom of the packages list.\n",
            "4.  Search for `pandas` and `numpy`, then click `Install Package`.\n",
            "\n",
            "**Verify Library Installation:**\n",
            "------------------------------\n",
            "\n",
            "After installation, you can verify that the libraries are installed correctly by opening a Python interpreter and importing the libraries:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "```\n",
            "\n",
            "If the libraries are installed correctly, you should not see any errors.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as assistant_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Check if agent has access to previous conversations\n"
      ],
      "metadata": {
        "id": "ERh9rRWcwv4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent, UserProxyAgent\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "from autogen_agentchat.task import MaxMessageTermination, TextMentionTermination\n",
        "\n",
        "\n",
        "code_writer_system_message = \"\"\"You are an AI assistant skilled in coding and language tasks. Provide solutions with Python (`python` code block) or shell script (`sh` code block).\n",
        "1. For info gathering, output necessary info (e.g., web browse, file read, system check). Use your language skills to solve the task after info is collected.\n",
        "2. For task execution, perform and output results. Clearly explain steps, indicating code or language skill. Solve step-by-step if needed. Plan first if not provided. Use full, executable code.\n",
        "Correct errors if they arise. Provide full code instead of partial solutions. Adapt approach if initial attempts fail.\n",
        "Do not formulate any type of conversation. Once you provide solution with code, End with 'TERMINATE'.\n",
        "\"\"\"\n",
        "\n",
        "text_termination = TextMentionTermination(\"TERMINATE\")\n",
        "\n",
        "code_writer_agent = ConversableAgent(\n",
        "    \"code_writer_agent\",\n",
        "    system_message=code_writer_system_message,\n",
        "    llm_config={\"config_list\": [{\"api_type\" : \"groq\",\n",
        "                                 \"model\": \"llama-3.2-90b-text-preview\",\n",
        "                                 \"api_key\": userdata.get(\"groq_api\"),\n",
        "                                 \"base_url\": \"https://api.groq.com/openai/v1\",\n",
        "                                 }]},\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    # is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"].lower(),\n",
        ")\n",
        "\n",
        "\n",
        "assistant_agent = UserProxyAgent(name=\"assistant_agent\", is_termination_msg=text_termination, human_input_mode='ALWAYS')\n",
        "\n",
        "chat_result = assistant_agent.initiate_chat(\n",
        "    code_writer_agent,\n",
        "    termination_condition=text_termination,\n",
        "    message=input(\"User : \"),\n",
        "    # max_turns=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRxD5IyouEi3",
        "outputId": "f0875824-29ab-4604-b82a-445be91b6bfb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User : code to print hello world\n",
            "assistant_agent (to code_writer_agent):\n",
            "\n",
            "code to print hello world\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to assistant_agent):\n",
            "\n",
            "```python\n",
            "# Hello World Program in Python\n",
            "\n",
            "def print_hello_world():\n",
            "    \"\"\"\n",
            "    Prints 'Hello, World!' to the console.\n",
            "    \"\"\"\n",
            "    print(\"Hello, World!\")\n",
            "\n",
            "# Call the function to print 'Hello, World!'\n",
            "print_hello_world()\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogen/oai/groq.py:280: UserWarning: Cost calculation not available for model llama-3.2-90b-text-preview\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Replying as assistant_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: what was the previous question that i asked you\n",
            "assistant_agent (to code_writer_agent):\n",
            "\n",
            "what was the previous question that i asked you\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to assistant_agent):\n",
            "\n",
            "You previously asked for code to print \"hello world\".\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as assistant_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: how did you approach that question\n",
            "assistant_agent (to code_writer_agent):\n",
            "\n",
            "how did you approach that question\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to assistant_agent):\n",
            "\n",
            "I approached that question by:\n",
            "\n",
            "1. Understanding the task: I recognized that the task was to write code that prints the string \"hello world\".\n",
            "2. Selecting a programming language: I chose Python as the programming language to write the code, as it is a popular and easy-to-understand language.\n",
            "3. Writing the code: I wrote a simple Python function `print_hello_world()` that uses the `print()` function to output the string \"Hello, World!\".\n",
            "4. Providing the solution: I provided the complete and executable Python code.\n",
            "\n",
            "I used my knowledge of Python programming language and coding best practices to provide a clear and concise solution to the task. I also included a docstring to explain the purpose of the function, but it's optional in this simple case.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as assistant_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ]
    }
  ]
}
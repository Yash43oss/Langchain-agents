{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+cQQVNVDOLsZP+kLGtyFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash43oss/Langchain-agents/blob/main/Agentic_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic RAG"
      ],
      "metadata": {
        "id": "NTULr7ilJ7b_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependancies"
      ],
      "metadata": {
        "id": "cWveQqCNKDsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1WUMNVWAcl42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f7322293-5330-48e9-bae1-2620a9249fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain_community langchain_groq bs4 faiss-cpu\n",
        "!pip install -qU langgraph\n",
        "!pip install -qU rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logic to scrape all relevant URLs from core base URL"
      ],
      "metadata": {
        "id": "NYgajbQtKIc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "\n",
        "def get_all_urls(base_url):\n",
        "    \"\"\"Scrape all URLs from base URL\n",
        "    Args:\n",
        "        base_url: str\n",
        "    Returns:\n",
        "        list of URLs\n",
        "    \"\"\"\n",
        "    reqs = requests.get(base_url)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        "\n",
        "    urls = []\n",
        "    for link in soup.find_all('a'):\n",
        "\n",
        "        href = link.get('href')\n",
        "        if href:\n",
        "            full_url = urljoin(base_url, href)\n",
        "            urls.append(full_url)\n",
        "    return urls\n",
        "\n",
        "base_url = 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/installation.html'\n",
        "all_urls = get_all_urls(base_url)\n",
        "print(len(all_urls))\n",
        "\n",
        "# Tool definition for end-to-end automation\n",
        "\n",
        "# url_tool = StructuredTool.from_function(func=get_all_urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVMARzb-N3ZE",
        "outputId": "d56aa688-2862-46b7-d6a9-af80acb012d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract all the information from the URLs"
      ],
      "metadata": {
        "id": "IRlGlwpBLSU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.web_base import WebBaseLoader\n",
        "from langchain.document_loaders.sitemap import SitemapLoader\n",
        "\n",
        "def page_loader(url: list[str]):\n",
        "  \"\"\"Extract URLs data from list of URLs\n",
        "  Args:\n",
        "    url: list[str]\n",
        "  Returns:\n",
        "    list of URLs data\n",
        "  \"\"\"\n",
        "  loader = WebBaseLoader(\n",
        "      web_path=url,\n",
        "      show_progress=True\n",
        "  )\n",
        "\n",
        "  doc = loader.load()\n",
        "  return doc\n",
        "source_docs = page_loader(url=all_urls)\n",
        "source_docs[0]\n",
        "\n",
        "# Tool definition for end-to-end automation\n",
        "\n",
        "# loader_tool = StructuredTool.from_function(func=page_loader)\n",
        "# loader_tool.invoke({'url': url})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DS7_RhbAHZHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dca9a55-7e14-4a1e-b99b-c2eb67d39d62"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/installation.html#main-content', 'title': 'Installation — AutoGen', 'description': 'Installing AutoGen AgentChat ', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\nInstallation — AutoGen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\nBack to top\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Choose version  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    AgentChat\\n  \\n\\n\\n\\n    Core\\n  \\n\\n\\n\\n    Extensions\\n  \\n\\n\\n\\n    Studio\\n  \\n\\n\\n\\n    API Reference\\n  \\n\\n\\n\\n    .NET\\n  \\n\\n\\n\\n                    More\\n                \\n\\n\\n\\n    0.2 Docs\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub\\n\\n\\n\\nDiscord\\n\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\n\\n\\nSearch\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    AgentChat\\n  \\n\\n\\n\\n    Core\\n  \\n\\n\\n\\n    Extensions\\n  \\n\\n\\n\\n    Studio\\n  \\n\\n\\n\\n    API Reference\\n  \\n\\n\\n\\n    .NET\\n  \\n\\n\\n\\n    0.2 Docs\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub\\n\\n\\n\\nDiscord\\n\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\n\\n\\n\\nInstallation\\nQuickstart\\nMigration Guide for v0.2 to v0.4\\n\\nTutorial\\n\\nIntroduction\\nModels\\nMessages\\nAgents\\nTeams\\nHuman-in-the-Loop\\nTermination\\nManaging State\\n\\nAdvanced\\n\\nCustom Agents\\nSelector Group Chat\\nSwarm\\nMagentic-One\\nGraphFlow (Workflows)\\nMemory and RAG\\nLogging\\nSerializing Components\\nTracing and Observability\\n\\nMore\\n\\nExamples\\nTravel Planning\\nCompany Research\\nLiterature Review\\n\\n\\n\\n\\n\\n\\n\\n                    API Reference\\n                \\n\\n\\n\\n\\n                    PyPi\\n                    \\n\\n\\n\\n\\n\\n                    Source\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAgentChat\\nInstallation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInstallation#\\n\\nCreate a Virtual Environment (optional)#\\nWhen installing AgentChat locally, we recommend using a virtual environment for the installation. This will ensure that the dependencies for AgentChat are isolated from the rest of your system.\\n\\n\\n\\nvenv\\nCreate and activate:\\n# On Windows, change `python3` to `python` (if `python` is Python 3).\\npython3 -m venv .venv\\n# On Windows, change `bin` to `scripts`.\\nsource .venv/bin/activate\\n\\n\\nTo deactivate later, run:\\ndeactivate\\n\\n\\n\\n\\n\\nconda\\nInstall Conda if you have not already.\\nCreate and activate:\\nconda create -n autogen python=3.12\\nconda activate autogen\\n\\n\\nTo deactivate later, run:\\nconda deactivate\\n\\n\\n\\n\\n\\n\\nInstall Using pip#\\nInstall the autogen-agentchat package using pip:\\npip install -U \"autogen-agentchat\"\\n\\n\\n\\nNote\\nPython 3.10 or later is required.\\n\\n\\n\\nInstall OpenAI for Model Client#\\nTo use the OpenAI and Azure OpenAI models, you need to install the following\\nextensions:\\npip install \"autogen-ext[openai]\"\\n\\n\\nIf you are using Azure OpenAI with AAD authentication, you need to install the following:\\npip install \"autogen-ext[azure]\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nprevious\\nAgentChat\\n\\n\\n\\n\\nnext\\nQuickstart\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n On this page\\n  \\n\\n\\nCreate a Virtual Environment (optional)\\nInstall Using pip\\nInstall OpenAI for Model Client\\n\\n\\n\\n\\n\\n\\n      \\n      \\n        \\n          Edit on GitHub\\n        \\n      \\n    \\n\\n\\n\\n\\n\\n Show Source\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n      Â© Copyright 2024, Microsoft.\\n      \\n\\n\\n\\n\\nPrivacy Policy | Consumer Health Privacy \\n\\n\\n\\n\\n  Built with the PyData Sphinx Theme 0.16.0.\\n\\n\\n\\n\\n\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking of extracted data"
      ],
      "metadata": {
        "id": "H6ylxeP1Lchm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.tools import tool\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from typing import List\n",
        "\n",
        "def chunk_documents(\n",
        "    docs: List[Document],\n",
        "    chunk_size: int = 500,\n",
        "    chunk_overlap: int = 100,\n",
        "    min_chunk_chars: int = 150\n",
        ") -> List[Document]:\n",
        "    \"\"\"\n",
        "    Splits documents into chunks while merging short chunks with previous ones\n",
        "    to maintain a meaningful minimum length.\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], is_separator_regex=True)\n",
        "    # splitter = MarkdownTextSplitter() ## Use if you are only interested in RAG based systems on MarkDown formatted documents\n",
        "    chunked_docs = []\n",
        "\n",
        "    for doc in docs:\n",
        "        chunks = splitter.split_text(doc.page_content)\n",
        "\n",
        "        merged_chunks = []\n",
        "        buffer = \"\"\n",
        "    # Ensure that len() of each chunk is not less than 150 before considering it as chunk\n",
        "        for chunk in chunks:\n",
        "            buffer += \" \" + chunk.strip()\n",
        "            if len(buffer.strip()) >= min_chunk_chars:\n",
        "                merged_chunks.append(buffer.strip())\n",
        "                buffer = \"\"\n",
        "\n",
        "        if buffer.strip():\n",
        "            merged_chunks.append(buffer.strip())\n",
        "\n",
        "        for chunk in merged_chunks:\n",
        "            chunked_docs.append(Document(page_content=chunk, metadata=doc.metadata))\n",
        "\n",
        "    return chunked_docs"
      ],
      "metadata": {
        "id": "sNiaARiobhrf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks = chunk_documents(source_docs)\n",
        "(document_chunks[50].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WPm9-vfNLMij",
        "outputId": "fa8c7447-6312-4276-c198-c80a7ccfd511"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Show Source\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n      © Copyright 2024, Microsoft.\\n      \\n\\n\\n\\n\\nPrivacy Policy | Consumer Health Privacy \\n\\n\\n\\n\\n  Built with the PyData Sphinx Theme 0.16.0.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding chunks to vector store for Information Retrieval"
      ],
      "metadata": {
        "id": "6lE41M9QMDNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up vectorstore globally or inject as needed\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "# Assume `processed_docs` is already available\n",
        "vectorstore = FAISS.from_documents(document_chunks, embedding_model)"
      ],
      "metadata": {
        "id": "Cz_4hWHnh0IZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom tool for Agentic RAG"
      ],
      "metadata": {
        "id": "BVdkbXSkM_hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def retrieve(inputs: str) -> str:\n",
        "    \"\"\"Retrieve the top_k most relevant document chunks for a given query.\n",
        "    The input must be a JSON string with 'query' and 'top_k'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        parsed = json.loads(inputs)\n",
        "        query = parsed[\"query\"]\n",
        "        top_k = int(parsed[\"top_k\"])\n",
        "    except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
        "        return f\"Invalid input format. Expected JSON string with 'query' and 'top_k'. Error: {str(e)}\"\n",
        "\n",
        "    docs = vectorstore.similarity_search(query, k=top_k)\n",
        "    return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "        [f\"\\n\\n===== Document {i} =====\\n{doc.page_content}\" for i, doc in enumerate(docs)]\n",
        "    )"
      ],
      "metadata": {
        "id": "ETiSG_gd5W8P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain Tool definition"
      ],
      "metadata": {
        "id": "3wQFb-0cNKha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"retriever\",\n",
        "        description=\"Uses FAISS vector search to retrieve parts of documentation most relevant to the query. Query and top_k required for information retrieval.\",\n",
        "        func=retrieve\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "IggvLkknAxCp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM Initialization"
      ],
      "metadata": {
        "id": "Nz0pDCyLNQ99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "groq_api = userdata.get('groq_api')\n",
        "llm = ChatGroq(api_key=groq_api, model=\"llama-3.3-70b-versatile\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbKbBOYnKMK8",
        "outputId": "35065701-41af-4e72-cad8-4edadc2eaf64"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x798a176b9d50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x798a176c7090>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReAct Prompt for Agentic RAG"
      ],
      "metadata": {
        "id": "oJOPWHD-NUNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "# prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWzB2fN6Zt-L",
        "outputId": "0a8baf94-2541-436b-9b4a-406503f14a23"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 1 - Tool based Agentic RAG using reAct"
      ],
      "metadata": {
        "id": "WjMjYxUhNd-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.react.agent import create_react_agent\n",
        "from langchain.agents.openai_tools.base import create_openai_tools_agent\n",
        "from langchain.agents import AgentExecutor, Agent\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "agent_executor.invoke({\"input\": \"how can you create agents using groupchat in autogen?\"})"
      ],
      "metadata": {
        "id": "7GJGTcuJYRVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd616814-4bbc-43c2-90b7-25d5858ed761"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the information on creating agents using groupchat in Autogen, I need to query the documentation. \n",
            "\n",
            "Action: retriever\n",
            "Action Input: query=\"creating agents using groupchat in Autogen\" and top_k=5\u001b[0m\u001b[36;1m\u001b[1;3mInvalid input format. Expected JSON string with 'query' and 'top_k'. Error: Expecting value: line 1 column 1 (char 0)\u001b[0m\u001b[32;1m\u001b[1;3mThought: It seems like the input format for the retriever function is incorrect. I need to format the input as a JSON string with 'query' and 'top_k' keys.\n",
            "\n",
            "Action: retriever\n",
            "Action Input: {\"query\": \"creating agents using groupchat in Autogen\", \"top_k\": 5}\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Retrieved documents:\n",
            "\n",
            "\n",
            "===== Document 0 =====\n",
            "All of the code to create a team should already be familiar to you.  An important note here is that all AgentChat agents and teams are run using the AutoGen core API runtime. In turn, the runtime is already instrumented to log [runtime messaging events (metadata)] (microsoft/autogen) including:\n",
            "\n",
            "===== Document 1 =====\n",
            "Start here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "===== Document 2 =====\n",
            "Start here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "===== Document 3 =====\n",
            "autogen_agentchat.agents\n",
            "AssistantAgent\n",
            "BaseChatAgent\n",
            "CodeExecutorAgent\n",
            "MessageFilterAgent\n",
            "MessageFilterConfig\n",
            "PerSourceFilter\n",
            "SocietyOfMindAgent\n",
            "UserProxyAgent\n",
            "\n",
            "\n",
            "autogen_agentchat.tools\n",
            "AgentTool\n",
            "TeamTool\n",
            "\n",
            "\n",
            "autogen_agentchat.teams\n",
            "BaseGroupChat\n",
            "DiGraph\n",
            "DiGraphBuilder\n",
            "DiGraphEdge\n",
            "DiGraphNode\n",
            "GraphFlow\n",
            "MagenticOneGroupChat\n",
            "RoundRobinGroupChat\n",
            "SelectorGroupChat\n",
            "Swarm\n",
            "\n",
            "===== Document 4 =====\n",
            "autogen_agentchat.agents\n",
            "AssistantAgent\n",
            "BaseChatAgent\n",
            "CodeExecutorAgent\n",
            "MessageFilterAgent\n",
            "MessageFilterConfig\n",
            "PerSourceFilter\n",
            "SocietyOfMindAgent\n",
            "UserProxyAgent\n",
            "\n",
            "\n",
            "autogen_agentchat.tools\n",
            "AgentTool\n",
            "TeamTool\n",
            "\n",
            "\n",
            "autogen_agentchat.teams\n",
            "BaseGroupChat\n",
            "DiGraph\n",
            "DiGraphBuilder\n",
            "DiGraphEdge\n",
            "DiGraphNode\n",
            "GraphFlow\n",
            "MagenticOneGroupChat\n",
            "RoundRobinGroupChat\n",
            "SelectorGroupChat\n",
            "Swarm\u001b[0m\u001b[32;1m\u001b[1;3mThought: Based on the retrieved documents, it seems that creating agents using groupchat in Autogen involves using the AutoGen core API runtime and the AgentChat framework. The framework provides a range of agents and tools for building conversational single and multi-agent applications.\n",
            "\n",
            "Action: retriever\n",
            "Action Input: {\"query\": \"AgentChat groupchat example\", \"top_k\": 5}\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Retrieved documents:\n",
            "\n",
            "\n",
            "===== Document 0 =====\n",
            "autogen_agentchat.agents\n",
            "AssistantAgent\n",
            "BaseChatAgent\n",
            "CodeExecutorAgent\n",
            "MessageFilterAgent\n",
            "MessageFilterConfig\n",
            "PerSourceFilter\n",
            "SocietyOfMindAgent\n",
            "UserProxyAgent\n",
            "\n",
            "\n",
            "autogen_agentchat.tools\n",
            "AgentTool\n",
            "TeamTool\n",
            "\n",
            "\n",
            "autogen_agentchat.teams\n",
            "BaseGroupChat\n",
            "DiGraph\n",
            "DiGraphBuilder\n",
            "DiGraphEdge\n",
            "DiGraphNode\n",
            "GraphFlow\n",
            "MagenticOneGroupChat\n",
            "RoundRobinGroupChat\n",
            "SelectorGroupChat\n",
            "Swarm\n",
            "\n",
            "===== Document 1 =====\n",
            "autogen_agentchat.agents\n",
            "AssistantAgent\n",
            "BaseChatAgent\n",
            "CodeExecutorAgent\n",
            "MessageFilterAgent\n",
            "MessageFilterConfig\n",
            "PerSourceFilter\n",
            "SocietyOfMindAgent\n",
            "UserProxyAgent\n",
            "\n",
            "\n",
            "autogen_agentchat.tools\n",
            "AgentTool\n",
            "TeamTool\n",
            "\n",
            "\n",
            "autogen_agentchat.teams\n",
            "BaseGroupChat\n",
            "DiGraph\n",
            "DiGraphBuilder\n",
            "DiGraphEdge\n",
            "DiGraphNode\n",
            "GraphFlow\n",
            "MagenticOneGroupChat\n",
            "RoundRobinGroupChat\n",
            "SelectorGroupChat\n",
            "Swarm\n",
            "\n",
            "===== Document 2 =====\n",
            "Ensure that you have optimized your single agent with the appropriate tools\n",
            "and instructions before moving to a team-based approach. Creating a Team#\n",
            "RoundRobinGroupChat is a simple yet effective team configuration where all agents share the same context and take turns responding in a round-robin fashion. Each agent, during its turn, broadcasts its response to all other agents, ensuring that the entire team maintains a consistent context.\n",
            "We will begin by creating a team with two AssistantAgent and a TextMentionTermination condition that stops the team when a specific word is detected in the agent’s response.\n",
            "\n",
            "===== Document 3 =====\n",
            "If you haven’t done so already, go through the AgentChat tutorial to learn about the concepts of AgentChat.\n",
            "Then, you can try swapping out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat.\n",
            "For example:\n",
            "import asyncio\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_agentchat.teams import MagenticOneGroupChat\n",
            "from autogen_agentchat.ui import Console\n",
            "\n",
            "===== Document 4 =====\n",
            "Source\n",
            "                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AgentChat\n",
            "Teams AgentChat\n",
            "Teams\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Teams#\n",
            "In this section you’ll learn how to create a multi-agent team (or simply team) using AutoGen. A team is a group of agents that work together to achieve a common goal.\n",
            "We’ll first show you how to create and run a team. We’ll then explain how to observe the team’s behavior, which is crucial for debugging and understanding the team’s performance, and common operations to control the team’s behavior.\n",
            "AgentChat supports several team presets:\u001b[0m\u001b[32;1m\u001b[1;3mThought: Based on the retrieved documents, it seems that creating agents using groupchat in Autogen involves using the AutoGen core API runtime and the AgentChat framework. The framework provides a range of agents and tools for building conversational single and multi-agent applications. To create a team, you can use the RoundRobinGroupChat or other team presets provided by AgentChat.\n",
            "\n",
            "Action: retriever\n",
            "Action Input: {\"query\": \"AgentChat team presets example\", \"top_k\": 5}\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Retrieved documents:\n",
            "\n",
            "\n",
            "===== Document 0 =====\n",
            "Source\n",
            "                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AgentChat\n",
            "Agents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Agents#\n",
            "AutoGen AgentChat provides a set of preset Agents, each with variations in how an agent might respond to messages.\n",
            "All agents share the following attributes and methods:\n",
            "\n",
            "===== Document 1 =====\n",
            "Source\n",
            "                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AgentChat\n",
            "Custom Agents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Custom Agents#\n",
            "You may have agents with behaviors that do not fall into a preset.\n",
            "In such cases, you can build custom agents.\n",
            "All agents in AgentChat inherit from BaseChatAgent\n",
            "class and implement the following abstract methods and attributes:\n",
            "\n",
            "===== Document 2 =====\n",
            "Source\n",
            "                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AgentChat\n",
            "Teams AgentChat\n",
            "Teams\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Teams#\n",
            "In this section you’ll learn how to create a multi-agent team (or simply team) using AutoGen. A team is a group of agents that work together to achieve a common goal.\n",
            "We’ll first show you how to create and run a team. We’ll then explain how to observe the team’s behavior, which is crucial for debugging and understanding the team’s performance, and common operations to control the team’s behavior.\n",
            "AgentChat supports several team presets:\n",
            "\n",
            "===== Document 3 =====\n",
            "If you haven’t done so already, go through the AgentChat tutorial to learn about the concepts of AgentChat.\n",
            "Then, you can try swapping out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat.\n",
            "For example:\n",
            "import asyncio\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_agentchat.teams import MagenticOneGroupChat\n",
            "from autogen_agentchat.ui import Console\n",
            "\n",
            "===== Document 4 =====\n",
            "Source\n",
            "                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "AgentChat\n",
            "Human-in-the-Loop\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Human-in-the-Loop#\n",
            "In the previous section Teams, we have seen how to create, observe,\n",
            "and control a team of agents.\n",
            "This section will focus on how to interact with the team from your application,\n",
            "and provide human feedback to the team.\n",
            "There are two main ways to interact with the team from your application:\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "\n",
            "Final Answer: To create agents using groupchat in Autogen, you can use the AutoGen core API runtime and the AgentChat framework. The framework provides a range of agents and tools for building conversational single and multi-agent applications. To create a team, you can use the RoundRobinGroupChat or other team presets provided by AgentChat, such as MagenticOneGroupChat or SelectorGroupChat. You can also build custom agents by inheriting from the BaseChatAgent class and implementing the required abstract methods and attributes. \n",
            "\n",
            "Here is an example of creating a team with two AssistantAgent and a TextMentionTermination condition:\n",
            "```python\n",
            "import asyncio\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_agentchat.teams import RoundRobinGroupChat\n",
            "from autogen_agentchat.ui import Console\n",
            "```\n",
            "You can also swap out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat:\n",
            "```python\n",
            "import asyncio\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_agentchat.teams import MagenticOneGroupChat\n",
            "from autogen_agentchat.ui import Console\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how can you create agents using groupchat in autogen?',\n",
              " 'output': 'To create agents using groupchat in Autogen, you can use the AutoGen core API runtime and the AgentChat framework. The framework provides a range of agents and tools for building conversational single and multi-agent applications. To create a team, you can use the RoundRobinGroupChat or other team presets provided by AgentChat, such as MagenticOneGroupChat or SelectorGroupChat. You can also build custom agents by inheriting from the BaseChatAgent class and implementing the required abstract methods and attributes. \\n\\nHere is an example of creating a team with two AssistantAgent and a TextMentionTermination condition:\\n```python\\nimport asyncio\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_agentchat.teams import RoundRobinGroupChat\\nfrom autogen_agentchat.ui import Console\\n```\\nYou can also swap out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat:\\n```python\\nimport asyncio\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_agentchat.teams import MagenticOneGroupChat\\nfrom autogen_agentchat.ui import Console\\n```'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 2 - Custom Tool calling Agentic RAG"
      ],
      "metadata": {
        "id": "OwZvXEp7Nvk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import StructuredTool\n",
        "\n",
        "def retrieve_fn(query: str, top_k: int) -> str:\n",
        "    docs = vectorstore.similarity_search(query, k=top_k)\n",
        "    return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "        [f\"\\n\\n===== Document {i} =====\\n{doc.page_content}\" for i, doc in enumerate(docs)]\n",
        "    )\n",
        "\n",
        "retrieve_tool = StructuredTool.from_function(\n",
        "    func=retrieve_fn,\n",
        "    name=\"retriever\",\n",
        "    description=\"Uses FAISS vector search to retrieve documentation. Requires 'query' and 'top_k'.\"\n",
        ")\n",
        "\n",
        "tools = [retrieve_tool]"
      ],
      "metadata": {
        "id": "x_eBDN9FHgkz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are an intelligent assistant with access to a retrieval tool. \"\n",
        "     \"Use the retriever tool as many times as needed until you gather sufficient, accurate information. \"\n",
        "     \"Reflect after each step whether the current information is enough to answer the user's query. \"\n",
        "     \"Avoid making assumptions; retrieve more if unsure. \"\n",
        "     \"Once confident, answer clearly.\"),\n",
        "\n",
        "    (\"placeholder\", \"{chat_history}\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])\n",
        "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "custom_agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "executor = AgentExecutor(agent=custom_agent, tools=tools, verbose=True)\n",
        "executor.invoke({\"input\": \"how can you create agents using groupchat in autogen?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiHG7Mb-2MVe",
        "outputId": "81831fac-155a-416e-c073-0e007fc6bbf8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `retriever` with `{'query': 'creating agents using groupchat in autogen', 'top_k': 5}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Retrieved documents:\n",
            "\n",
            "\n",
            "===== Document 0 =====\n",
            "All of the code to create a team should already be familiar to you.  An important note here is that all AgentChat agents and teams are run using the AutoGen core API runtime. In turn, the runtime is already instrumented to log [runtime messaging events (metadata)] (microsoft/autogen) including:\n",
            "\n",
            "===== Document 1 =====\n",
            "Start here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "===== Document 2 =====\n",
            "Start here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "===== Document 3 =====\n",
            "autogen_agentchat.agents\n",
            "AssistantAgent\n",
            "BaseChatAgent\n",
            "CodeExecutorAgent\n",
            "MessageFilterAgent\n",
            "MessageFilterConfig\n",
            "PerSourceFilter\n",
            "SocietyOfMindAgent\n",
            "UserProxyAgent\n",
            "\n",
            "\n",
            "autogen_agentchat.tools\n",
            "AgentTool\n",
            "TeamTool\n",
            "\n",
            "\n",
            "autogen_agentchat.teams\n",
            "BaseGroupChat\n",
            "DiGraph\n",
            "DiGraphBuilder\n",
            "DiGraphEdge\n",
            "DiGraphNode\n",
            "GraphFlow\n",
            "MagenticOneGroupChat\n",
            "RoundRobinGroupChat\n",
            "SelectorGroupChat\n",
            "Swarm\n",
            "\n",
            "===== Document 4 =====\n",
            "autogen_agentchat.agents\n",
            "AssistantAgent\n",
            "BaseChatAgent\n",
            "CodeExecutorAgent\n",
            "MessageFilterAgent\n",
            "MessageFilterConfig\n",
            "PerSourceFilter\n",
            "SocietyOfMindAgent\n",
            "UserProxyAgent\n",
            "\n",
            "\n",
            "autogen_agentchat.tools\n",
            "AgentTool\n",
            "TeamTool\n",
            "\n",
            "\n",
            "autogen_agentchat.teams\n",
            "BaseGroupChat\n",
            "DiGraph\n",
            "DiGraphBuilder\n",
            "DiGraphEdge\n",
            "DiGraphNode\n",
            "GraphFlow\n",
            "MagenticOneGroupChat\n",
            "RoundRobinGroupChat\n",
            "SelectorGroupChat\n",
            "Swarm\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `retriever` with `{'query': 'autogen group chat example', 'top_k': 5}`\n",
            "responded: Based on the retrieved documents, it appears that creating agents using group chat in AutoGen involves using the AutoGen core API runtime and the AgentChat framework. The AgentChat framework provides a programming framework for building conversational single and multi-agent applications.\n",
            "\n",
            "To create agents using group chat, you can use the `autogen_agentchat.agents` module, which provides various agent classes such as `AssistantAgent`, `BaseChatAgent`, `CodeExecutorAgent`, and more. You can also use the `autogen_agentchat.teams` module, which provides classes for creating group chats, such as `BaseGroupChat`, `DiGraph`, `DiGraphBuilder`, and more.\n",
            "\n",
            "Here is an example of how you can create an agent using group chat:\n",
            "```\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "# Create an assistant agent\n",
            "agent = AssistantAgent()\n",
            "\n",
            "# Create a group chat\n",
            "group_chat = BaseGroupChat()\n",
            "\n",
            "# Add the agent to the group chat\n",
            "group_chat.add_agent(agent)\n",
            "\n",
            "# Start the group chat\n",
            "asyncio.run(group_chat.start())\n",
            "```\n",
            "This code creates an assistant agent and adds it to a group chat. The group chat is then started using the `start()` method.\n",
            "\n",
            "Note that this is just a basic example, and you may need to customize the agent and group chat to suit your specific use case. Additionally, you may need to install the required libraries and dependencies, such as `autogen-agentchat` and `autogen-ext`, using pip.\n",
            "\n",
            "I hope this helps! Let me know if you have any further questions. \n",
            "\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Retrieved documents:\n",
            "\n",
            "\n",
            "===== Document 0 =====\n",
            "Group Chat#\n",
            "In v0.2, you need to create a GroupChat class and pass it into a\n",
            "GroupChatManager, and have a participant that is a user proxy to initiate the chat.\n",
            "For a simple scenario of a writer and a critic, you can do the following:\n",
            "from autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "===== Document 1 =====\n",
            "RoundRobinGroupChat: A team that runs a group chat with participants taking turns in a round-robin fashion (covered on this page). Tutorial\n",
            "SelectorGroupChat: A team that selects the next speaker using a ChatCompletion model after each message. Tutorial\n",
            "MagenticOneGroupChat: A  generalist multi-agent system for solving open-ended web and file-based tasks across a variety of domains. Tutorial\n",
            "Swarm: A team that uses HandoffMessage to signal transitions between agents. Tutorial\n",
            "\n",
            "===== Document 2 =====\n",
            "Note\n",
            "SelectorGroupChat is a high-level API. For more control and customization, refer to the Group Chat Pattern in the Core API documentation to implement your own group chat logic.\n",
            "\n",
            "\n",
            "How Does it Work?#\n",
            "SelectorGroupChat is a group chat similar to RoundRobinGroupChat,\n",
            "but with a model-based next speaker selection mechanism.\n",
            "When the team receives a task through run() or run_stream(),\n",
            "the following steps are executed:\n",
            "\n",
            "===== Document 3 =====\n",
            "asyncio.run(main())\n",
            "\n",
            "\n",
            "When using tool-equipped agents inside a group chat such as\n",
            "RoundRobinGroupChat,\n",
            "you simply do the same as above to add tools to the agents, and create a\n",
            "group chat with the agents.\n",
            "\n",
            "===== Document 4 =====\n",
            "Group Chat with Resume#\n",
            "In v0.2, group chat with resume is a bit complicated. You need to explicitly\n",
            "save the group chat messages and load them back when you want to resume the chat.\n",
            "See Resuming Group Chat in v0.2 for more details.\n",
            "In v0.4, you can simply call run or run_stream again with the same group chat object to resume the chat. To export and load the state, you can use\n",
            "save_state and load_state methods.\n",
            "import asyncio\n",
            "import json\n",
            "from autogen_agentchat.agents import AssistantAgent\u001b[0m\u001b[32;1m\u001b[1;3mTo create agents using group chat in AutoGen, you can use the `GroupChat` class and pass it into a `GroupChatManager`. You can also use pre-built group chat teams such as `RoundRobinGroupChat`, `SelectorGroupChat`, `MagenticOneGroupChat`, and `Swarm`. These teams can be used to create a group chat with participants taking turns in a round-robin fashion, selecting the next speaker using a ChatCompletion model, or using a generalist multi-agent system for solving open-ended tasks. \n",
            "\n",
            "Here is an example of how to create a simple group chat:\n",
            "```\n",
            "from autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "# Create agents\n",
            "agent1 = AssistantAgent(llm_config)\n",
            "agent2 = AssistantAgent(llm_config)\n",
            "\n",
            "# Create a group chat\n",
            "group_chat = GroupChat([agent1, agent2])\n",
            "\n",
            "# Create a group chat manager\n",
            "group_chat_manager = GroupChatManager(group_chat)\n",
            "\n",
            "# Run the group chat\n",
            "group_chat_manager.run()\n",
            "```\n",
            "This code creates two agents using the `AssistantAgent` class and a group chat using the `GroupChat` class. It then creates a group chat manager using the `GroupChatManager` class and runs the group chat using the `run` method. \n",
            "\n",
            "You can also use the `RoundRobinGroupChat` team to create a group chat with participants taking turns in a round-robin fashion. Here is an example:\n",
            "```\n",
            "from autogen.agentchat import RoundRobinGroupChat, AssistantAgent\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "# Create agents\n",
            "agent1 = AssistantAgent(llm_config)\n",
            "agent2 = AssistantAgent(llm_config)\n",
            "\n",
            "# Create a round robin group chat\n",
            "group_chat = RoundRobinGroupChat([agent1, agent2])\n",
            "\n",
            "# Run the group chat\n",
            "group_chat.run()\n",
            "```\n",
            "This code creates two agents using the `AssistantAgent` class and a round robin group chat using the `RoundRobinGroupChat` class. It then runs the group chat using the `run` method. \n",
            "\n",
            "You can also use the `SelectorGroupChat` team to create a group chat that selects the next speaker using a ChatCompletion model. Here is an example:\n",
            "```\n",
            "from autogen.agentchat import SelectorGroupChat, AssistantAgent\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "# Create agents\n",
            "agent1 = AssistantAgent(llm_config)\n",
            "agent2 = AssistantAgent(llm_config)\n",
            "\n",
            "# Create a selector group chat\n",
            "group_chat = SelectorGroupChat([agent1, agent2])\n",
            "\n",
            "# Run the group chat\n",
            "group_chat.run()\n",
            "```\n",
            "This code creates two agents using the `AssistantAgent` class and a selector group chat using the `SelectorGroupChat` class. It then runs the group chat using the `run` method. \n",
            "\n",
            "You can also use the `MagenticOneGroupChat` team to create a generalist multi-agent system for solving open-ended tasks. Here is an example:\n",
            "```\n",
            "from autogen.agentchat import MagenticOneGroupChat, AssistantAgent\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "# Create agents\n",
            "agent1 = AssistantAgent(llm_config)\n",
            "agent2 = AssistantAgent(llm_config)\n",
            "\n",
            "# Create a magentic one group chat\n",
            "group_chat = MagenticOneGroupChat([agent1, agent2])\n",
            "\n",
            "# Run the group chat\n",
            "group_chat.run()\n",
            "```\n",
            "This code creates two agents using the `AssistantAgent` class and a magentic one group chat using the `MagenticOneGroupChat` class. It then runs the group chat using the `run` method. \n",
            "\n",
            "You can also use the `Swarm` team to create a group chat that uses HandoffMessage to signal transitions between agents. Here is an example:\n",
            "```\n",
            "from autogen.agentchat import Swarm, AssistantAgent\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "# Create agents\n",
            "agent1 = AssistantAgent(llm_config)\n",
            "agent2 = AssistantAgent(llm_config)\n",
            "\n",
            "# Create a swarm\n",
            "group_chat = Swarm([agent1, agent2])\n",
            "\n",
            "# Run the group chat\n",
            "group_chat.run()\n",
            "```\n",
            "This code creates two agents using the `AssistantAgent` class and a swarm using the `Swarm` class. It then runs the group chat using the `run` method. \n",
            "\n",
            "Note that these are just examples and you may need to modify the code to fit your specific use case. Additionally, you will need to have the necessary dependencies installed and configured in order to run the code.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how can you create agents using groupchat in autogen?',\n",
              " 'output': 'To create agents using group chat in AutoGen, you can use the `GroupChat` class and pass it into a `GroupChatManager`. You can also use pre-built group chat teams such as `RoundRobinGroupChat`, `SelectorGroupChat`, `MagenticOneGroupChat`, and `Swarm`. These teams can be used to create a group chat with participants taking turns in a round-robin fashion, selecting the next speaker using a ChatCompletion model, or using a generalist multi-agent system for solving open-ended tasks. \\n\\nHere is an example of how to create a simple group chat:\\n```\\nfrom autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}\\n\\n# Create agents\\nagent1 = AssistantAgent(llm_config)\\nagent2 = AssistantAgent(llm_config)\\n\\n# Create a group chat\\ngroup_chat = GroupChat([agent1, agent2])\\n\\n# Create a group chat manager\\ngroup_chat_manager = GroupChatManager(group_chat)\\n\\n# Run the group chat\\ngroup_chat_manager.run()\\n```\\nThis code creates two agents using the `AssistantAgent` class and a group chat using the `GroupChat` class. It then creates a group chat manager using the `GroupChatManager` class and runs the group chat using the `run` method. \\n\\nYou can also use the `RoundRobinGroupChat` team to create a group chat with participants taking turns in a round-robin fashion. Here is an example:\\n```\\nfrom autogen.agentchat import RoundRobinGroupChat, AssistantAgent\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}\\n\\n# Create agents\\nagent1 = AssistantAgent(llm_config)\\nagent2 = AssistantAgent(llm_config)\\n\\n# Create a round robin group chat\\ngroup_chat = RoundRobinGroupChat([agent1, agent2])\\n\\n# Run the group chat\\ngroup_chat.run()\\n```\\nThis code creates two agents using the `AssistantAgent` class and a round robin group chat using the `RoundRobinGroupChat` class. It then runs the group chat using the `run` method. \\n\\nYou can also use the `SelectorGroupChat` team to create a group chat that selects the next speaker using a ChatCompletion model. Here is an example:\\n```\\nfrom autogen.agentchat import SelectorGroupChat, AssistantAgent\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}\\n\\n# Create agents\\nagent1 = AssistantAgent(llm_config)\\nagent2 = AssistantAgent(llm_config)\\n\\n# Create a selector group chat\\ngroup_chat = SelectorGroupChat([agent1, agent2])\\n\\n# Run the group chat\\ngroup_chat.run()\\n```\\nThis code creates two agents using the `AssistantAgent` class and a selector group chat using the `SelectorGroupChat` class. It then runs the group chat using the `run` method. \\n\\nYou can also use the `MagenticOneGroupChat` team to create a generalist multi-agent system for solving open-ended tasks. Here is an example:\\n```\\nfrom autogen.agentchat import MagenticOneGroupChat, AssistantAgent\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}\\n\\n# Create agents\\nagent1 = AssistantAgent(llm_config)\\nagent2 = AssistantAgent(llm_config)\\n\\n# Create a magentic one group chat\\ngroup_chat = MagenticOneGroupChat([agent1, agent2])\\n\\n# Run the group chat\\ngroup_chat.run()\\n```\\nThis code creates two agents using the `AssistantAgent` class and a magentic one group chat using the `MagenticOneGroupChat` class. It then runs the group chat using the `run` method. \\n\\nYou can also use the `Swarm` team to create a group chat that uses HandoffMessage to signal transitions between agents. Here is an example:\\n```\\nfrom autogen.agentchat import Swarm, AssistantAgent\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}\\n\\n# Create agents\\nagent1 = AssistantAgent(llm_config)\\nagent2 = AssistantAgent(llm_config)\\n\\n# Create a swarm\\ngroup_chat = Swarm([agent1, agent2])\\n\\n# Run the group chat\\ngroup_chat.run()\\n```\\nThis code creates two agents using the `AssistantAgent` class and a swarm using the `Swarm` class. It then runs the group chat using the `run` method. \\n\\nNote that these are just examples and you may need to modify the code to fit your specific use case. Additionally, you will need to have the necessary dependencies installed and configured in order to run the code.'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 3 - Vector store retrieving Agentic RAG"
      ],
      "metadata": {
        "id": "GFvm0hedOaaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "ret_tool = create_retriever_tool(\n",
        "    retriever = vectorstore.as_retriever(),\n",
        "    name=\"retrieve_documentations\",\n",
        "    description=\"Search and return information about documentation.\",\n",
        ")\n",
        "\n",
        "ret_agent = create_tool_calling_agent(llm=llm, tools=[ret_tool], prompt = prompt)\n",
        "executor = AgentExecutor(agent=ret_agent, tools=[ret_tool], verbose=True)\n",
        "executor.invoke({\"input\": \"create agents in python\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUtQH4rNCcj",
        "outputId": "3fd87f79-d891-4184-d5ad-d0218f88ae5d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `retrieve_documentations` with `{'query': 'creating agents in python'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mStart here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "Start here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "# Create the primary agent.\n",
            "    primary_agent = AssistantAgent(\n",
            "        \"primary_agent\",\n",
            "        model_client=model_client,\n",
            "        system_message=\"You are a helpful AI assistant.\",\n",
            "    )\n",
            "\n",
            "    # Create the critic agent.\n",
            "    critic_agent = AssistantAgent(\n",
            "        \"critic_agent\",\n",
            "        model_client=model_client,\n",
            "        system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
            "    )\n",
            "\n",
            "# Create the primary agent.\n",
            "primary_agent = AssistantAgent(\n",
            "    \"primary\",\n",
            "    model_client=model_client,\n",
            "    system_message=\"You are a helpful AI assistant.\",\n",
            ")\n",
            "\n",
            "# Create the critic agent.\n",
            "critic_agent = AssistantAgent(\n",
            "    \"critic\",\n",
            "    model_client=model_client,\n",
            "    system_message=\"Provide constructive feedback for every message. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
            ")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `retrieve_documentations` with `{'query': 'python library for creating agents'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mStart here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "Start here if you are new to AutoGen and want to prototype with agents without writing code.\n",
            "\n",
            "\n",
            "Get Started\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " AgentChat\n",
            "\n",
            "\n",
            "A programming framework for building conversational single and multi-agent applications.\n",
            "Built on Core. Requires Python 3.10+.\n",
            "# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "â†‘ Back to Top â†‘\n",
            "  \n",
            "\n",
            "   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "About\n",
            "\n",
            "        A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "microsoft.github.io/autogen/\n",
            "\n",
            "\n",
            "Topics\n",
            "\n",
            "\n",
            "\n",
            "  framework\n",
            "\n",
            "\n",
            "  ai\n",
            "\n",
            "\n",
            "  agents\n",
            "\n",
            "\n",
            "  autogen\n",
            "\n",
            "\n",
            "  chatgpt\n",
            "\n",
            "\n",
            "  llm-agent\n",
            "\n",
            "\n",
            "  agentic\n",
            "\n",
            "\n",
            "  llm-framework\n",
            "\n",
            "\n",
            "  agentic-agi\n",
            "\n",
            "\n",
            "  autogen-ecosystem\n",
            "\n",
            "\n",
            "\n",
            "Resources\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        Readme\n",
            " \n",
            "License\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      CC-BY-4.0, MIT licenses found\n",
            "\n",
            "â†‘ Back to Top â†‘\n",
            "  \n",
            "\n",
            "   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "About\n",
            "\n",
            "        A programming framework for agentic AI ðŸ¤– PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "microsoft.github.io/autogen/\n",
            "\n",
            "\n",
            "Topics\n",
            "\n",
            "\n",
            "\n",
            "  framework\n",
            "\n",
            "\n",
            "  ai\n",
            "\n",
            "\n",
            "  agents\n",
            "\n",
            "\n",
            "  autogen\n",
            "\n",
            "\n",
            "  chatgpt\n",
            "\n",
            "\n",
            "  llm-agent\n",
            "\n",
            "\n",
            "  agentic\n",
            "\n",
            "\n",
            "  llm-framework\n",
            "\n",
            "\n",
            "  agentic-agi\n",
            "\n",
            "\n",
            "  autogen-ecosystem\n",
            "\n",
            "\n",
            "\n",
            "Resources\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        Readme\n",
            " \n",
            "License\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      CC-BY-4.0, MIT licenses found\u001b[0m\u001b[32;1m\u001b[1;3mYou can create agents in Python using the autogen-agentchat library. You can install it using pip:\n",
            "\n",
            "```bash\n",
            "pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\n",
            "```\n",
            "\n",
            "Here's an example of how to create agents:\n",
            "\n",
            "```python\n",
            "import asyncio\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
            "\n",
            "# Create the primary agent.\n",
            "primary_agent = AssistantAgent(\n",
            "    \"primary\",\n",
            "    model_client=model_client,\n",
            "    system_message=\"You are a helpful AI assistant.\",\n",
            ")\n",
            "\n",
            "# Create the critic agent.\n",
            "critic_agent = AssistantAgent(\n",
            "    \"critic\",\n",
            "    model_client=model_client,\n",
            "    system_message=\"Provide constructive feedback for every message. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
            ")\n",
            "```\n",
            "\n",
            "You can find more information about the autogen-agentchat library on the official GitHub page: https://microsoft.github.io/autogen/.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'create agents in python',\n",
              " 'output': 'You can create agents in Python using the autogen-agentchat library. You can install it using pip:\\n\\n```bash\\npip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\\n```\\n\\nHere\\'s an example of how to create agents:\\n\\n```python\\nimport asyncio\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\\n\\n# Create the primary agent.\\nprimary_agent = AssistantAgent(\\n    \"primary\",\\n    model_client=model_client,\\n    system_message=\"You are a helpful AI assistant.\",\\n)\\n\\n# Create the critic agent.\\ncritic_agent = AssistantAgent(\\n    \"critic\",\\n    model_client=model_client,\\n    system_message=\"Provide constructive feedback for every message. Respond with \\'APPROVE\\' to when your feedbacks are addressed.\",\\n)\\n```\\n\\nYou can find more information about the autogen-agentchat library on the official GitHub page: https://microsoft.github.io/autogen/.'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 4 - Advanced Retrieval Augmentaed Generation(ARAG) concepts"
      ],
      "metadata": {
        "id": "Hn9NtD_KPH9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.ensemble import EnsembleRetriever\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_ret = BM25Retriever.from_documents(document_chunks)\n",
        "# bm25_retriever = bm25_ret.as_retriever()\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_ret, vectorstore.as_retriever()], weights=[0.5, 0.5]\n",
        ")\n",
        "ensemble_ret_tool = ensemble_retriever.as_tool()\n",
        "\n",
        "ensemble_ret_agent = create_tool_calling_agent(llm=llm, tools=[ensemble_ret_tool], prompt = prompt)\n",
        "executor = AgentExecutor(agent=ensemble_ret_agent, tools=[ensemble_ret_tool], verbose=True)\n",
        "executor.invoke({\"input\": \"how can you create agents using groupchat in autogen?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyjjZ4ViRpsY",
        "outputId": "8f1fbb3a-9846-49f3-b01f-de98bc14d7c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6898009c543b>:10: LangChainBetaWarning: This API is in beta and may change in the future.\n",
            "  ensemble_ret_tool = ensemble_retriever.as_tool()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EnsembleRetriever` with `{'title': 'Creating agents using groupchat in Autogen'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(id='ebfd3955-5a35-454f-9bc4-bd3166137aea', metadata={'source': 'https://microsoft.github.io/autogen/stable/index.html', 'title': 'AutoGen — AutoGen', 'description': 'Top-level documentation for AutoGen, a framework for developing applications using AI agents ', 'language': 'en'}, page_content='Start here if you are new to AutoGen and want to prototype with agents without writing code.\\n\\n\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n AgentChat\\n\\n\\nA programming framework for building conversational single and multi-agent applications.\\nBuilt on Core. Requires Python 3.10+.\\n# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\\nimport asyncio\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient'), Document(metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/company-research.html', 'title': 'Company Research — AutoGen', 'language': 'en'}, page_content='Creating the Team#\\nFinally, let’s create a team of the three agents and set them to work on researching a company.\\n\\n\\nteam = RoundRobinGroupChat([stock_analysis_agent, search_agent, report_agent], max_turns=3)\\n\\n\\n\\n\\nWe use max_turns=3 to limit the number of turns to exactly the same number of agents in the team. This effectively makes the agents work in a sequential manner.\\n\\n\\nstream = team.run_stream(task=\"Write a financial report on American airlines\")\\nawait Console(stream)'), Document(id='61592e6b-47a5-40ce-84f5-bacf79a3c7fc', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tracing.html', 'title': 'Tracing and Observability — AutoGen', 'language': 'en'}, page_content='All of the code to create a team should already be familiar to you.  An important note here is that all AgentChat agents and teams are run using the AutoGen core API runtime. In turn, the runtime is already instrumented to log [runtime messaging events (metadata)] (microsoft/autogen) including:'), Document(metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/index.html', 'title': 'Examples — AutoGen', 'description': 'Examples built using AgentChat, a high-level api for AutoGen ', 'language': 'en'}, page_content='company research: Generating a company research report using multiple agents with tools.\\n\\n\\n\\n\\n\\n\\n\\n\\nLiterature Review\\nGenerating a literature review using agents with tools.\\n\\nliterature review: Generating a literature review using agents with tools.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nprevious\\nTracing and Observability\\n\\n\\n\\n\\nnext\\nTravel Planning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n      \\n        \\n          Edit on GitHub\\n        \\n      \\n    \\n\\n\\n\\n\\n\\n Show Source\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n      Â© Copyright 2024, Microsoft.'), Document(metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html', 'title': 'Migration Guide for v0.2 to v0.4 — AutoGen', 'language': 'en'}, page_content='# Create a group chat with the writer and critic.\\ngroupchat = GroupChat(agents=[writer, critic], messages=[], max_round=12)\\n\\n# Create a group chat manager to manage the group chat, use round-robin selection method.\\nmanager = GroupChatManager(groupchat=groupchat, llm_config=llm_config, speaker_selection_method=\"round_robin\")'), Document(metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/literature-review.html', 'title': 'Literature Review — AutoGen', 'language': 'en'}, page_content='Creating the Team#\\nFinally, we will create a team of agents and configure them to perform the tasks.\\n\\n\\ntermination = TextMentionTermination(\"TERMINATE\")\\nteam = RoundRobinGroupChat(\\n    participants=[google_search_agent, arxiv_search_agent, report_agent], termination_condition=termination\\n)\\n\\n\\n\\n\\n\\n\\nawait Console(\\n    team.run_stream(\\n        task=\"Write a literature review on no code tools for building multi agent ai systems\",\\n    )\\n)\\n\\nawait model_client.close()'), Document(id='7601de50-9c34-4cb2-a0a4-251ad1144fac', metadata={'source': 'https://microsoft.github.io/autogen/stable/reference/index.html', 'title': 'API Reference — AutoGen', 'description': 'AutoGen is a community-driven project. Learn how to get involved, contribute, and connect with the community. ', 'language': 'en'}, page_content='autogen_agentchat.agents\\nAssistantAgent\\nBaseChatAgent\\nCodeExecutorAgent\\nMessageFilterAgent\\nMessageFilterConfig\\nPerSourceFilter\\nSocietyOfMindAgent\\nUserProxyAgent\\n\\n\\nautogen_agentchat.tools\\nAgentTool\\nTeamTool\\n\\n\\nautogen_agentchat.teams\\nBaseGroupChat\\nDiGraph\\nDiGraphBuilder\\nDiGraphEdge\\nDiGraphNode\\nGraphFlow\\nMagenticOneGroupChat\\nRoundRobinGroupChat\\nSelectorGroupChat\\nSwarm')]\u001b[0m\u001b[32;1m\u001b[1;3mTo create agents using group chat in Autogen, you can use the `GroupChat` class from the `autogen_agentchat` module. This class allows you to create a group chat with multiple agents and manage the conversation between them.\n",
            "\n",
            "Here is an example of how to create a group chat with two agents:\n",
            "```\n",
            "from autogen_agentchat.agents import AssistantAgent\n",
            "from autogen_agentchat.teams import GroupChat\n",
            "\n",
            "# Create two agents\n",
            "agent1 = AssistantAgent()\n",
            "agent2 = AssistantAgent()\n",
            "\n",
            "# Create a group chat with the two agents\n",
            "groupchat = GroupChat(agents=[agent1, agent2], messages=[], max_round=12)\n",
            "```\n",
            "You can also use the `RoundRobinGroupChat` class to create a group chat where the agents take turns speaking:\n",
            "```\n",
            "from autogen_agentchat.teams import RoundRobinGroupChat\n",
            "\n",
            "# Create two agents\n",
            "agent1 = AssistantAgent()\n",
            "agent2 = AssistantAgent()\n",
            "\n",
            "# Create a round-robin group chat with the two agents\n",
            "groupchat = RoundRobinGroupChat(agents=[agent1, agent2], max_turns=3)\n",
            "```\n",
            "You can also add a termination condition to the group chat to stop the conversation after a certain number of turns:\n",
            "```\n",
            "from autogen_agentchat.teams import RoundRobinGroupChat\n",
            "from autogen_agentchat.termination import TextMentionTermination\n",
            "\n",
            "# Create two agents\n",
            "agent1 = AssistantAgent()\n",
            "agent2 = AssistantAgent()\n",
            "\n",
            "# Create a round-robin group chat with the two agents and a termination condition\n",
            "termination = TextMentionTermination(\"TERMINATE\")\n",
            "groupchat = RoundRobinGroupChat(agents=[agent1, agent2], termination_condition=termination)\n",
            "```\n",
            "You can then use the `run_stream` method to start the conversation and get the output:\n",
            "```\n",
            "from autogen_agentchat.teams import RoundRobinGroupChat\n",
            "\n",
            "# Create two agents\n",
            "agent1 = AssistantAgent()\n",
            "agent2 = AssistantAgent()\n",
            "\n",
            "# Create a round-robin group chat with the two agents\n",
            "groupchat = RoundRobinGroupChat(agents=[agent1, agent2], max_turns=3)\n",
            "\n",
            "# Start the conversation and get the output\n",
            "output = groupchat.run_stream(task=\"Write a financial report on American airlines\")\n",
            "```\n",
            "Note that the `run_stream` method returns a stream of messages, which you can then process and display as needed.\n",
            "\n",
            "I hope this helps! Let me know if you have any questions or need further assistance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how can you create agents using groupchat in autogen?',\n",
              " 'output': 'To create agents using group chat in Autogen, you can use the `GroupChat` class from the `autogen_agentchat` module. This class allows you to create a group chat with multiple agents and manage the conversation between them.\\n\\nHere is an example of how to create a group chat with two agents:\\n```\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_agentchat.teams import GroupChat\\n\\n# Create two agents\\nagent1 = AssistantAgent()\\nagent2 = AssistantAgent()\\n\\n# Create a group chat with the two agents\\ngroupchat = GroupChat(agents=[agent1, agent2], messages=[], max_round=12)\\n```\\nYou can also use the `RoundRobinGroupChat` class to create a group chat where the agents take turns speaking:\\n```\\nfrom autogen_agentchat.teams import RoundRobinGroupChat\\n\\n# Create two agents\\nagent1 = AssistantAgent()\\nagent2 = AssistantAgent()\\n\\n# Create a round-robin group chat with the two agents\\ngroupchat = RoundRobinGroupChat(agents=[agent1, agent2], max_turns=3)\\n```\\nYou can also add a termination condition to the group chat to stop the conversation after a certain number of turns:\\n```\\nfrom autogen_agentchat.teams import RoundRobinGroupChat\\nfrom autogen_agentchat.termination import TextMentionTermination\\n\\n# Create two agents\\nagent1 = AssistantAgent()\\nagent2 = AssistantAgent()\\n\\n# Create a round-robin group chat with the two agents and a termination condition\\ntermination = TextMentionTermination(\"TERMINATE\")\\ngroupchat = RoundRobinGroupChat(agents=[agent1, agent2], termination_condition=termination)\\n```\\nYou can then use the `run_stream` method to start the conversation and get the output:\\n```\\nfrom autogen_agentchat.teams import RoundRobinGroupChat\\n\\n# Create two agents\\nagent1 = AssistantAgent()\\nagent2 = AssistantAgent()\\n\\n# Create a round-robin group chat with the two agents\\ngroupchat = RoundRobinGroupChat(agents=[agent1, agent2], max_turns=3)\\n\\n# Start the conversation and get the output\\noutput = groupchat.run_stream(task=\"Write a financial report on American airlines\")\\n```\\nNote that the `run_stream` method returns a stream of messages, which you can then process and display as needed.\\n\\nI hope this helps! Let me know if you have any questions or need further assistance.'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 5 - Multi-query Retrieval using custom LLM chain"
      ],
      "metadata": {
        "id": "i7dUdlf0PviQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "custom_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are an AI assistant that helps improve information retrieval from a vector database.\n",
        "Your task is to rewrite the following user question into **five semantically diverse** but relevant versions.\n",
        "These variations should explore different phrasings, related concepts, and subquestions that could help uncover useful results in a similarity-based search system.\n",
        "\n",
        "Focus on:\n",
        "- Rewriting the question using synonyms or alternative formulations.\n",
        "- Asking the same question from different angles or using different terminology.\n",
        "- Breaking the question into smaller related sub-queries, if appropriate.\n",
        "\n",
        "Your output should be a list of **exactly five variations**, each on a new line, with **no numbering or bullets**, like:\n",
        "variation one\n",
        "variation two\n",
        "variation three\n",
        "variation four\n",
        "variation five\n",
        "\n",
        "# ORIGINAL QUESTION:\n",
        "{question}\n",
        "\n",
        "# Rewritten Queries:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "custom_multiquery_chain = (\n",
        "    {\"question\": RunnablePassthrough()} | custom_prompt | llm | StrOutputParser()\n",
        ")\n",
        "\n",
        "question = \"What are the applications of autogen?\"\n",
        "multi_queries = custom_multiquery_chain.invoke(question)\n",
        "print(multi_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxJBNPzBVPbt",
        "outputId": "75929512-3321-4092-ec76-b95d22ad62dc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the uses of automatic code generation tools\n",
            "How does autogen impact software development and its various applications\n",
            "What role does autogen play in streamlining development processes and workflows\n",
            "In what ways can autogen be utilized to improve coding efficiency and productivity\n",
            "What are the potential benefits and real-world implications of implementing autogen in different programming contexts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "    llm=custom_multiquery_chain, retriever=vectorstore.as_retriever()\n",
        ")\n",
        "# relevant_docs = multiquery_retriever.invoke(question)\n",
        "mul_ret_tool = multiquery_retriever.as_tool()\n",
        "# print(len(relevant_docs))\n",
        "# print(print(relevant_docs[0].page_content))\n",
        "mul_ret_agent = create_tool_calling_agent(llm=llm, tools=[mul_ret_tool], prompt = prompt)\n",
        "executor = AgentExecutor(agent=mul_ret_agent, tools=[mul_ret_tool], verbose=True)\n",
        "executor.invoke({\"input\": \"how can you create agents using groupchat in autogen?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TByzY9HVVvY3",
        "outputId": "eaf206fb-0f42-46e5-c002-34c5956bd2ec"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `MultiQueryRetriever` with `{'title': 'Creating agents using group chat in Autogen'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(id='ebfd3955-5a35-454f-9bc4-bd3166137aea', metadata={'source': 'https://microsoft.github.io/autogen/stable/index.html', 'title': 'AutoGen — AutoGen', 'description': 'Top-level documentation for AutoGen, a framework for developing applications using AI agents ', 'language': 'en'}, page_content='Start here if you are new to AutoGen and want to prototype with agents without writing code.\\n\\n\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n AgentChat\\n\\n\\nA programming framework for building conversational single and multi-agent applications.\\nBuilt on Core. Requires Python 3.10+.\\n# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\\nimport asyncio\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient'), Document(id='b5919bac-2b9a-4bd1-9a63-3a475b5d75c0', metadata={'source': 'https://microsoft.github.io/autogen/stable/index.html', 'title': 'AutoGen — AutoGen', 'description': 'Top-level documentation for AutoGen, a framework for developing applications using AI agents ', 'language': 'en'}, page_content='Start here if you are new to AutoGen and want to prototype with agents without writing code.\\n\\n\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n AgentChat\\n\\n\\nA programming framework for building conversational single and multi-agent applications.\\nBuilt on Core. Requires Python 3.10+.\\n# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\\nimport asyncio\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient'), Document(id='d5e8eb76-dccf-4cab-ab7c-47811da0dfaf', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html', 'title': 'Migration Guide for v0.2 to v0.4 — AutoGen', 'language': 'en'}, page_content='Group Chat#\\nIn v0.2, you need to create a GroupChat class and pass it into a\\nGroupChatManager, and have a participant that is a user proxy to initiate the chat.\\nFor a simple scenario of a writer and a critic, you can do the following:\\nfrom autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}'), Document(id='a525029f-9f9e-4820-b636-7a5f78a2da7c', metadata={'source': 'https://microsoft.github.io/autogen/0.2/', 'title': 'AutoGen | AutoGen 0.2', 'description': 'Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework', 'language': 'en'}, page_content='BlogGitHubTwitterctrlKAutoGen 0.2An Open-Source Programming Framework for Agentic AIGet started with 0.4The new event driven, asynchronous architecture for AutoGenContinue with 0.2Multi-Agent Conversation FrameworkAutoGen provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.Easily Build Diverse ApplicationsAutoGen offers a collection of working systems spanning a wide range of applications from various domains and'), Document(id='109557a3-f0e8-4d57-b941-6cbda08fd9e8', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html', 'title': 'AutoGen Studio — AutoGen', 'description': 'User Guide for AutoGen Studio - A low code tool for building and debugging multi-agent systems ', 'language': 'en'}, page_content='Source\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio#\\n\\n\\nAutoGen Studio is a low-code interface built to help you rapidly prototype AI agents, enhance them with tools, compose them into teams and interact with them to accomplish tasks. It is built on AutoGen AgentChat - a high-level API for building multi-agent applications.\\n\\nSee a video tutorial on AutoGen Studio v0.4 (02/25) - https://youtu.be/oum6EI7wohM'), Document(id='895b211c-96e9-47f1-a93d-4615f06558d6', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html', 'title': 'AutoGen Studio — AutoGen', 'description': 'User Guide for AutoGen Studio - A low code tool for building and debugging multi-agent systems ', 'language': 'en'}, page_content='Source\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio#\\n\\n\\nAutoGen Studio is a low-code interface built to help you rapidly prototype AI agents, enhance them with tools, compose them into teams and interact with them to accomplish tasks. It is built on AutoGen AgentChat - a high-level API for building multi-agent applications.\\n\\nSee a video tutorial on AutoGen Studio v0.4 (02/25) - https://youtu.be/oum6EI7wohM')]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `MultiQueryRetriever` with `{'title': 'Creating agents using group chat in Autogen with specific code'}`\n",
            "responded: To create agents using group chat in Autogen, you can use the GroupChat class and pass it into a GroupChatManager. You also need to have a participant that is a user proxy to initiate the chat. Here's an example:\n",
            "\n",
            "```python\n",
            "from autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "```\n",
            "\n",
            "You can create a GroupChat class and pass it into a GroupChatManager, and have a participant that is a user proxy to initiate the chat. For a simple scenario of a writer and a critic, you can do the following:\n",
            "\n",
            "```python\n",
            "from autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "```\n",
            "\n",
            "You can also use AutoGen Studio, a low-code interface built to help you rapidly prototype AI agents, enhance them with tools, compose them into teams, and interact with them to accomplish tasks. It is built on AutoGen AgentChat - a high-level API for building multi-agent applications.\n",
            "\n",
            "Please note that you need to have the necessary dependencies installed, such as `autogen-agentchat` and `autogen-ext[openai]`, and you need to have a valid API key for the language model you want to use.\n",
            "\n",
            "If you need more information or have specific questions, feel free to ask. \n",
            "\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(id='ebfd3955-5a35-454f-9bc4-bd3166137aea', metadata={'source': 'https://microsoft.github.io/autogen/stable/index.html', 'title': 'AutoGen — AutoGen', 'description': 'Top-level documentation for AutoGen, a framework for developing applications using AI agents ', 'language': 'en'}, page_content='Start here if you are new to AutoGen and want to prototype with agents without writing code.\\n\\n\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n AgentChat\\n\\n\\nA programming framework for building conversational single and multi-agent applications.\\nBuilt on Core. Requires Python 3.10+.\\n# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\\nimport asyncio\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient'), Document(id='b5919bac-2b9a-4bd1-9a63-3a475b5d75c0', metadata={'source': 'https://microsoft.github.io/autogen/stable/index.html', 'title': 'AutoGen — AutoGen', 'description': 'Top-level documentation for AutoGen, a framework for developing applications using AI agents ', 'language': 'en'}, page_content='Start here if you are new to AutoGen and want to prototype with agents without writing code.\\n\\n\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n AgentChat\\n\\n\\nA programming framework for building conversational single and multi-agent applications.\\nBuilt on Core. Requires Python 3.10+.\\n# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\\nimport asyncio\\nfrom autogen_agentchat.agents import AssistantAgent\\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient'), Document(id='e743bbc7-a994-4153-94f9-d9f955cedcde', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/literature-review.html', 'title': 'Literature Review — AutoGen', 'language': 'en'}, page_content='started\\\\\\\\nexploiting large language models (LLM) to lessen such burden and increase the\\\\\\\\nusability of AutoML frameworks via a natural language interface, allowing\\\\\\\\nnon-expert users to build their data-driven solutions. These methods, however,\\\\\\\\nare usually designed only for a particular process in the AI development\\\\\\\\npipeline and do not efficiently use the inherent capacity of the LLMs. This\\\\\\\\npaper proposes AutoML-Agent, a novel multi-agent framework tailored for\\\\\\\\nfull-pipeline AutoML,'), Document(id='d51c175b-8c5a-4539-90cc-0779e99bf69a', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/literature-review.html', 'title': 'Literature Review — AutoGen', 'language': 'en'}, page_content='AI development by automating\\\\\\\\ntasks in the development pipeline, such as optimal model search and\\\\\\\\nhyperparameter tuning. Existing AutoML systems often require technical\\\\\\\\nexpertise to set up complex tools, which is in general time-consuming and\\\\\\\\nrequires a large amount of human effort. Therefore, recent works have started\\\\\\\\nexploiting large language models (LLM) to lessen such burden and increase the\\\\\\\\nusability of AutoML frameworks via a natural language interface, allowing\\\\\\\\nnon-expert'), Document(id='d5e8eb76-dccf-4cab-ab7c-47811da0dfaf', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html', 'title': 'Migration Guide for v0.2 to v0.4 — AutoGen', 'language': 'en'}, page_content='Group Chat#\\nIn v0.2, you need to create a GroupChat class and pass it into a\\nGroupChatManager, and have a participant that is a user proxy to initiate the chat.\\nFor a simple scenario of a writer and a critic, you can do the following:\\nfrom autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}'), Document(id='8c657f72-2743-4325-92f1-7af9a52ccdb8', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html', 'title': 'Migration Guide for v0.2 to v0.4 — AutoGen', 'language': 'en'}, page_content='Two-Agent Chat#\\nIn v0.2, you can create a two-agent chat for code execution as follows:\\nfrom autogen.coding import LocalCommandLineCodeExecutor\\nfrom autogen.agentchat import AssistantAgent, UserProxyAgent\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}'), Document(id='109557a3-f0e8-4d57-b941-6cbda08fd9e8', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html', 'title': 'AutoGen Studio — AutoGen', 'description': 'User Guide for AutoGen Studio - A low code tool for building and debugging multi-agent systems ', 'language': 'en'}, page_content='Source\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio#\\n\\n\\nAutoGen Studio is a low-code interface built to help you rapidly prototype AI agents, enhance them with tools, compose them into teams and interact with them to accomplish tasks. It is built on AutoGen AgentChat - a high-level API for building multi-agent applications.\\n\\nSee a video tutorial on AutoGen Studio v0.4 (02/25) - https://youtu.be/oum6EI7wohM'), Document(id='895b211c-96e9-47f1-a93d-4615f06558d6', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html', 'title': 'AutoGen Studio — AutoGen', 'description': 'User Guide for AutoGen Studio - A low code tool for building and debugging multi-agent systems ', 'language': 'en'}, page_content='Source\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutoGen Studio#\\n\\n\\nAutoGen Studio is a low-code interface built to help you rapidly prototype AI agents, enhance them with tools, compose them into teams and interact with them to accomplish tasks. It is built on AutoGen AgentChat - a high-level API for building multi-agent applications.\\n\\nSee a video tutorial on AutoGen Studio v0.4 (02/25) - https://youtu.be/oum6EI7wohM'), Document(id='29f71e82-ee72-4c48-b6ca-6b90badabf67', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/literature-review.html', 'title': 'Literature Review — AutoGen', 'language': 'en'}, page_content=\"reusable agent components. We\\\\\\\\nhighlight four design principles for no-code multi-agent developer tools and\\\\\\\\ncontribute an open-source implementation at\\\\\\\\nhttps://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio\\\\', \\\\'pdf_url\\\\': \\\\'http://arxiv.org/pdf/2408.15247v1\\\\'}, {\\\\'title\\\\': \\\\'Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration\\\\', \\\\'authors\\\\': [\\\\'Cory Hymel\\\\', \\\\'Sida Peng\\\\', \\\\'Kevin Xu\\\\', \\\\'Charath Ranganathan\\\\'], \\\\'published\\\\':\"), Document(id='58302bd5-d0cc-42d6-a36d-f627b0354d85', metadata={'source': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/literature-review.html', 'title': 'Literature Review — AutoGen', 'language': 'en'}, page_content=\"agent components. We\\\\nhighlight four design principles for no-code multi-agent developer tools and\\\\ncontribute an open-source implementation at\\\\nhttps://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio', 'pdf_url': 'http://arxiv.org/pdf/2408.15247v1'}, {'title': 'Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration', 'authors': ['Cory Hymel', 'Sida Peng', 'Kevin Xu', 'Charath Ranganathan'], 'published': '2024-10-29', 'abstract': 'In recent\")]\u001b[0m\u001b[32;1m\u001b[1;3mTo create agents using group chat in Autogen, you can use the GroupChat class and pass it into a GroupChatManager. You can also use the AssistantAgent class to create a simple scenario of a writer and a critic. \n",
            "\n",
            "Here's an example of how to create a GroupChat:\n",
            "\n",
            "```\n",
            "from autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\n",
            "\n",
            "llm_config = {\n",
            "    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\n",
            "    \"seed\": 42,\n",
            "    \"temperature\": 0,\n",
            "}\n",
            "\n",
            "# Create a GroupChatManager\n",
            "group_chat_manager = GroupChatManager(llm_config)\n",
            "\n",
            "# Create a GroupChat\n",
            "group_chat = GroupChat(group_chat_manager)\n",
            "\n",
            "# Create an AssistantAgent\n",
            "assistant_agent = AssistantAgent(llm_config)\n",
            "\n",
            "# Add the AssistantAgent to the GroupChat\n",
            "group_chat.add_participant(assistant_agent)\n",
            "```\n",
            "\n",
            "You can also use the UserProxyAgent class to create a user proxy to initiate the chat.\n",
            "\n",
            "```\n",
            "from autogen.agentchat import AssistantAgent, UserProxyAgent\n",
            "\n",
            "# Create a UserProxyAgent\n",
            "user_proxy_agent = UserProxyAgent(llm_config)\n",
            "\n",
            "# Add the UserProxyAgent to the GroupChat\n",
            "group_chat.add_participant(user_proxy_agent)\n",
            "```\n",
            "\n",
            "You can then use the GroupChat to initiate a conversation between the agents.\n",
            "\n",
            "```\n",
            "# Initiate a conversation\n",
            "group_chat.initiate_conversation()\n",
            "```\n",
            "\n",
            "This is a basic example of how to create agents using group chat in Autogen. You can customize the agents and the conversation to suit your specific needs.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how can you create agents using groupchat in autogen?',\n",
              " 'output': 'To create agents using group chat in Autogen, you can use the GroupChat class and pass it into a GroupChatManager. You can also use the AssistantAgent class to create a simple scenario of a writer and a critic. \\n\\nHere\\'s an example of how to create a GroupChat:\\n\\n```\\nfrom autogen.agentchat import AssistantAgent, GroupChat, GroupChatManager\\n\\nllm_config = {\\n    \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": \"sk-xxx\"}],\\n    \"seed\": 42,\\n    \"temperature\": 0,\\n}\\n\\n# Create a GroupChatManager\\ngroup_chat_manager = GroupChatManager(llm_config)\\n\\n# Create a GroupChat\\ngroup_chat = GroupChat(group_chat_manager)\\n\\n# Create an AssistantAgent\\nassistant_agent = AssistantAgent(llm_config)\\n\\n# Add the AssistantAgent to the GroupChat\\ngroup_chat.add_participant(assistant_agent)\\n```\\n\\nYou can also use the UserProxyAgent class to create a user proxy to initiate the chat.\\n\\n```\\nfrom autogen.agentchat import AssistantAgent, UserProxyAgent\\n\\n# Create a UserProxyAgent\\nuser_proxy_agent = UserProxyAgent(llm_config)\\n\\n# Add the UserProxyAgent to the GroupChat\\ngroup_chat.add_participant(user_proxy_agent)\\n```\\n\\nYou can then use the GroupChat to initiate a conversation between the agents.\\n\\n```\\n# Initiate a conversation\\ngroup_chat.initiate_conversation()\\n```\\n\\nThis is a basic example of how to create agents using group chat in Autogen. You can customize the agents and the conversation to suit your specific needs.'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VWx7Oe_W0pu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}